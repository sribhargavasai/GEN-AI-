{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4ityi4aH8Eqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d08d99-6289-4332-9733-7fd31dc26e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, gensim\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 scipy-1.13.1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gensim\n",
        "import gensim\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "?Word2Vec"
      ],
      "metadata": {
        "id": "pfMgHyrZuk8z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = [\n",
        "    'talk.religion.misc',\n",
        "    'comp.graphics',\n",
        "    'sci.space',\n",
        "]\n",
        "\n",
        "print(\"Loading 20 newsgroups dataset for categories:\")\n",
        "print(categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCSGFO-eQGnq",
        "outputId": "1476b575-394e-4cbd-b09c-f85700a16086"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 20 newsgroups dataset for categories:\n",
            "['talk.religion.misc', 'comp.graphics', 'sci.space']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = fetch_20newsgroups(subset='all', categories=categories,\n",
        "                             shuffle=False, remove=('headers', 'footers', 'quotes'))\n",
        "labels = df.target\n",
        "true_k = len(np.unique(labels)) ## This should be 3 in this example\n",
        "print(true_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar0RiWqCQQbP",
        "outputId": "ffc3303e-9800-466d-e2b2-defed783d934"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhTAVQur-Hs8",
        "outputId": "5210e6ec-3ca9-468b-f9eb-832e5b82b47b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2588"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.target[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_RckI7JQg92",
        "outputId": "989a244b-de57-4715-e1c0-1c92ce5b652c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ru603XFQoS4",
        "outputId": "258da8e9-12af-4e54-8e5a-7f7eb19be777"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2588"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]\n",
        "for text in df.data:\n",
        "  data.append(text)"
      ],
      "metadata": {
        "id": "l_UuGCPGQ0Lr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "61SNMVuKQ_hd",
        "outputId": "f95c8755-b37f-4064-f5ef-bd0d798bdd09"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nI think I can. Largely as a result of efforts by people reading this group\\nwriting letters and making phone calls the following has happened:\\n\\n1. NASA reprogrammed funds to keep NASP alive in 1991.\\n2. Efforts to kill DC-X and the SSRT progam where twice twarted\\n   (Feb. and June of last year).\\n3. Gouldin kept his job in spite of heavy lobbying against him.\\n\\nThis may not be what Mark was thinking of but it shows that the\\nreaders of sci.space DO have power and influence.\\n\\n  Allen\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new=[]\n",
        "for i in data:\n",
        "  i=re.sub('[\\s+\\d+:\\.\\)\\( ]',' ',i) #'\\.' spaces, numbers, colon, paranthesis, full stop rmoval\n",
        "  i=re.sub(r'\\S*@\\S*\\s?','',i)  # Email removal\n",
        "  new.append(i)\n",
        "\n",
        "new[0:3]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzv66CZrRCYU",
        "outputId": "10a33797-c936-4cc6-bd77-6379ddd65faa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  I think I can  Largely as a result of efforts by people reading this group writing letters and making phone calls the following has happened      NASA reprogrammed funds to keep NASP alive in          Efforts to kill DC-X and the SSRT progam where twice twarted     Feb  and June of last year      Gouldin kept his job in spite of heavy lobbying against him   This may not be what Mark was thinking of but it shows that the readers of sci space DO have power and influence     Allen ',\n",
              " 'In regards to fractal commpression, I have seen   fractal compressed \"movies\"  They were both fairly impressive   The first one was a    gray scale \"movie\" of Casablanca, it was    MB and had    minutes of    fps video   It was a little grainy but not bad at all   The second one I saw was only   minutes but it had   bit color with   fps and measured in at    MB   I consider the fractal movies a practical thing to explore   But unlike many  other formats out there, you do end up losing resolution   I don\\'t know what kind of software/hardware was used for creating the \"movies\" I saw but the guy that showed them to me said it took  -   minutes per frame to generate   But as I said above playback was    or more frames per second   And how else could you put    minutes on one floppy disk?',\n",
              " 'Background  The Orion spacedrive was a theoretical concept   It would be a drive using thermonuclear explosions to drive a spacecraft  The idea was that you\\'d detonate devices with somewhere from one to ten megatons yield behind a \"pusher plate\" attached to the main spacecraft   The shock wave from the explosions would transfer momentum to the ship     Now, in an atmosphere I can see this   The energy of the explosion heats the atmosphere, which expands explosively and slams a shock wave into the pusher plate   But in a vacuum, only two things I can see are going to hit the plate  fission/fusion products  barium, krypton, helium, neutrons, evaporated bomb casing  and electromagnetic radiation  gammas mostly, some light/heat from irradiated fission products      Would this work?  I can\\'t see the EM radiation impelling very much momentum  especially given the mass of the pusher plate , and it seems to me you\\'re going to get more momentum transfer throwing the bombs out the back of the ship than you get from detonating them once they\\'re there     I must be missing something   Would someone enlighten me via email?    Thanks   --   --Jim ']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aINrss1idyDD",
        "outputId": "6bf205a1-05f4-4def-f154-9bea38c5db30"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "tokens=[]\n",
        "for text in new:\n",
        "  text= re.sub(r'\\s+',' ',text.lower())\n",
        "  tokens.append(word_tokenize(text))"
      ],
      "metadata": {
        "id": "N0M-TFvNbPB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71255956-5b57-4aa6-cd0c-a0e8d1f1bf4f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvkMLi49qTkd",
        "outputId": "162e8a27-8026-4c2c-c8be-65a7a274c010"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['i',\n",
              "  'think',\n",
              "  'i',\n",
              "  'can',\n",
              "  'largely',\n",
              "  'as',\n",
              "  'a',\n",
              "  'result',\n",
              "  'of',\n",
              "  'efforts',\n",
              "  'by',\n",
              "  'people',\n",
              "  'reading',\n",
              "  'this',\n",
              "  'group',\n",
              "  'writing',\n",
              "  'letters',\n",
              "  'and',\n",
              "  'making',\n",
              "  'phone',\n",
              "  'calls',\n",
              "  'the',\n",
              "  'following',\n",
              "  'has',\n",
              "  'happened',\n",
              "  'nasa',\n",
              "  'reprogrammed',\n",
              "  'funds',\n",
              "  'to',\n",
              "  'keep',\n",
              "  'nasp',\n",
              "  'alive',\n",
              "  'in',\n",
              "  'efforts',\n",
              "  'to',\n",
              "  'kill',\n",
              "  'dc-x',\n",
              "  'and',\n",
              "  'the',\n",
              "  'ssrt',\n",
              "  'progam',\n",
              "  'where',\n",
              "  'twice',\n",
              "  'twarted',\n",
              "  'feb',\n",
              "  'and',\n",
              "  'june',\n",
              "  'of',\n",
              "  'last',\n",
              "  'year',\n",
              "  'gouldin',\n",
              "  'kept',\n",
              "  'his',\n",
              "  'job',\n",
              "  'in',\n",
              "  'spite',\n",
              "  'of',\n",
              "  'heavy',\n",
              "  'lobbying',\n",
              "  'against',\n",
              "  'him',\n",
              "  'this',\n",
              "  'may',\n",
              "  'not',\n",
              "  'be',\n",
              "  'what',\n",
              "  'mark',\n",
              "  'was',\n",
              "  'thinking',\n",
              "  'of',\n",
              "  'but',\n",
              "  'it',\n",
              "  'shows',\n",
              "  'that',\n",
              "  'the',\n",
              "  'readers',\n",
              "  'of',\n",
              "  'sci',\n",
              "  'space',\n",
              "  'do',\n",
              "  'have',\n",
              "  'power',\n",
              "  'and',\n",
              "  'influence',\n",
              "  'allen'],\n",
              " ['in',\n",
              "  'regards',\n",
              "  'to',\n",
              "  'fractal',\n",
              "  'commpression',\n",
              "  ',',\n",
              "  'i',\n",
              "  'have',\n",
              "  'seen',\n",
              "  'fractal',\n",
              "  'compressed',\n",
              "  '``',\n",
              "  'movies',\n",
              "  \"''\",\n",
              "  'they',\n",
              "  'were',\n",
              "  'both',\n",
              "  'fairly',\n",
              "  'impressive',\n",
              "  'the',\n",
              "  'first',\n",
              "  'one',\n",
              "  'was',\n",
              "  'a',\n",
              "  'gray',\n",
              "  'scale',\n",
              "  '``',\n",
              "  'movie',\n",
              "  \"''\",\n",
              "  'of',\n",
              "  'casablanca',\n",
              "  ',',\n",
              "  'it',\n",
              "  'was',\n",
              "  'mb',\n",
              "  'and',\n",
              "  'had',\n",
              "  'minutes',\n",
              "  'of',\n",
              "  'fps',\n",
              "  'video',\n",
              "  'it',\n",
              "  'was',\n",
              "  'a',\n",
              "  'little',\n",
              "  'grainy',\n",
              "  'but',\n",
              "  'not',\n",
              "  'bad',\n",
              "  'at',\n",
              "  'all',\n",
              "  'the',\n",
              "  'second',\n",
              "  'one',\n",
              "  'i',\n",
              "  'saw',\n",
              "  'was',\n",
              "  'only',\n",
              "  'minutes',\n",
              "  'but',\n",
              "  'it',\n",
              "  'had',\n",
              "  'bit',\n",
              "  'color',\n",
              "  'with',\n",
              "  'fps',\n",
              "  'and',\n",
              "  'measured',\n",
              "  'in',\n",
              "  'at',\n",
              "  'mb',\n",
              "  'i',\n",
              "  'consider',\n",
              "  'the',\n",
              "  'fractal',\n",
              "  'movies',\n",
              "  'a',\n",
              "  'practical',\n",
              "  'thing',\n",
              "  'to',\n",
              "  'explore',\n",
              "  'but',\n",
              "  'unlike',\n",
              "  'many',\n",
              "  'other',\n",
              "  'formats',\n",
              "  'out',\n",
              "  'there',\n",
              "  ',',\n",
              "  'you',\n",
              "  'do',\n",
              "  'end',\n",
              "  'up',\n",
              "  'losing',\n",
              "  'resolution',\n",
              "  'i',\n",
              "  'do',\n",
              "  \"n't\",\n",
              "  'know',\n",
              "  'what',\n",
              "  'kind',\n",
              "  'of',\n",
              "  'software/hardware',\n",
              "  'was',\n",
              "  'used',\n",
              "  'for',\n",
              "  'creating',\n",
              "  'the',\n",
              "  '``',\n",
              "  'movies',\n",
              "  \"''\",\n",
              "  'i',\n",
              "  'saw',\n",
              "  'but',\n",
              "  'the',\n",
              "  'guy',\n",
              "  'that',\n",
              "  'showed',\n",
              "  'them',\n",
              "  'to',\n",
              "  'me',\n",
              "  'said',\n",
              "  'it',\n",
              "  'took',\n",
              "  '-',\n",
              "  'minutes',\n",
              "  'per',\n",
              "  'frame',\n",
              "  'to',\n",
              "  'generate',\n",
              "  'but',\n",
              "  'as',\n",
              "  'i',\n",
              "  'said',\n",
              "  'above',\n",
              "  'playback',\n",
              "  'was',\n",
              "  'or',\n",
              "  'more',\n",
              "  'frames',\n",
              "  'per',\n",
              "  'second',\n",
              "  'and',\n",
              "  'how',\n",
              "  'else',\n",
              "  'could',\n",
              "  'you',\n",
              "  'put',\n",
              "  'minutes',\n",
              "  'on',\n",
              "  'one',\n",
              "  'floppy',\n",
              "  'disk',\n",
              "  '?']]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter Explanation:\n",
        "\n",
        "tokens: The input tokenized sentences (list of lists of words).\n",
        "\n",
        "size=50: Each word will be represented as a 50-dimensional vector.\n",
        "\n",
        "window=5: The context window size (words within 5 positions before/after the target word are considered).\n",
        "\n",
        "sg=1: Use Skip-Gram (instead of CBOW, which is sg=0).\n",
        "\n",
        "hs=0: Use negative sampling instead of hierarchical softmax.\n",
        "\n",
        "iter=10: Train the model for 10 iterations over the corpus."
      ],
      "metadata": {
        "id": "w5FKFwuNVnLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Gensim_model = Word2Vec(tokens, vector_size=50, window=5, sg=1, hs=0, epochs=10) # Changed 'iter' to 'epochs'"
      ],
      "metadata": {
        "id": "1FFSMBv_qW8m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1='software'\n",
        "Gensim_model.wv.most_similar(positive=w1,topn=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrNkAG8ytsAX",
        "outputId": "fa1e7fc3-7cae-4f35-fecd-f233bb685b76"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ijg', 0.7279137372970581),\n",
              " ('portable', 0.7190135717391968),\n",
              " ('annotation', 0.7146681547164917),\n",
              " ('handmade', 0.7140646576881409)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1='science'\n",
        "Gensim_model.wv.most_similar(positive=w1,topn=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0aj8Sj5uJpD",
        "outputId": "9791a29d-add5-4c75-9ba2-1875f1c14256"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('advancement', 0.7254958152770996),\n",
              " ('institute', 0.7164019346237183),\n",
              " ('sciences', 0.7143131494522095),\n",
              " ('engineering', 0.7090082764625549)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1='technology'\n",
        "Gensim_model.wv.most_similar(positive=w1,topn=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0-iSFfwuRpM",
        "outputId": "c6eba6f8-446c-46f7-ad19-95c154554998"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('aerospace', 0.8501653671264648),\n",
              " ('marketing', 0.7891271114349365),\n",
              " ('national', 0.7881510853767395),\n",
              " ('transportation', 0.7872278094291687)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Gensim_model.wv.get_vector('science')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DselQrGTuea1",
        "outputId": "d432ac9f-56e5-4f08-a7a9-4104f5f392ab"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.13336034,  0.05287362,  0.17764056,  0.40690023,  0.11138757,\n",
              "       -0.20343252,  0.37245798,  0.6571998 , -0.3651773 , -0.74844086,\n",
              "        0.0273826 ,  0.20383343, -0.3543113 , -0.12256496, -0.23001662,\n",
              "        0.51569396,  1.1805788 ,  0.67994636, -0.37951118, -0.37080574,\n",
              "       -0.23213503,  0.32312652,  0.9238566 , -0.11214881, -0.1433974 ,\n",
              "       -0.14516342, -0.09017952, -0.04072703, -0.6863302 , -0.16174878,\n",
              "        0.09512826,  0.31952345,  0.31932008, -0.6373651 , -0.53669757,\n",
              "        0.02514499, -0.7125027 , -0.04510448, -0.00494487,  0.12629578,\n",
              "        0.2555158 , -0.14129794,  0.3044474 , -0.12851265, -0.04972406,\n",
              "       -0.6491015 ,  0.16210906, -0.6344667 ,  0.7551902 , -0.49492723],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Gensim_model.wv.most_similar('Gastroenteritis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "7dbq1eEIgBWN",
        "outputId": "949656b8-4a25-4c87-9e25-63f50a444806"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Key 'Gastroenteritis' not present in vocabulary\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8ef265523844>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGensim_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Gastroenteritis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         all_keys = [\n\u001b[1;32m    843\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key 'Gastroenteritis' not present in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "model_fast = FastText(tokens, size=100, window=5, min_count=5, workers=4,sg=1) # religion, space and graphics"
      ],
      "metadata": {
        "id": "0GayZBYfum3C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "86d383ce-8dc8-4fab-9e1e-3be80eaf561f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "FastText.__init__() got an unexpected keyword argument 'size'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-413e1f38244e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_fast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# religion, space and graphics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: FastText.__init__() got an unexpected keyword argument 'size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_fast.wv.most_similar(\"Gastroenteritis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "2wcnQbvTvIgQ",
        "outputId": "826a8c4f-404a-4a10-d507-f0ab3c441498"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_fast' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-989a502c5092>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gastroenteritis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_fast' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "?model_fast.wv.most_similar"
      ],
      "metadata": {
        "id": "gdYRyQRtlXUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15adc4e0-d236-40bf-afb3-56cfbf51f023"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object `model_fast.wv.most_similar` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "?FastText()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HknwIzLH7Eo5",
        "outputId": "f88c4d96-cf62-473a-860f-02fb0f770ae8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object `FastText()` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TOQVPQPKEcUw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}